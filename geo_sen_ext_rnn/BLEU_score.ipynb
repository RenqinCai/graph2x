{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sacrebleu\n",
    "from sacremoses import MosesDetokenizer, MosesTokenizer\n",
    "md = MosesDetokenizer(lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = MosesTokenizer(lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pred = \"pred.txt\"  # Test file argument\n",
    "target_ref = \"ref.txt\"  # MTed file argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ref = \"ref_large.txt\"  # MTed file argument\n",
    "\n",
    "with open(target_ref, \"w\") as ref:\n",
    "    for i in range(1000000):\n",
    "        line = \"the dog bit the man.\\n\"\n",
    "        ref.write(line)\n",
    "        line = \"it was not unexpected.\\n\"\n",
    "        ref.write(line)\n",
    "        line = \"the man bit him first.\\n\"\n",
    "        ref.write(line)\n",
    "\n",
    "target_pred = \"pred_large.txt\"  # Test file argument\n",
    "\n",
    "with open(target_pred, \"w\") as pred:\n",
    "    for i in range(1000000):\n",
    "        line = \"the dog bit the man.\\n\"\n",
    "        pred.write(line)\n",
    "        line = \"it wasn't surprising.\\n\"\n",
    "        pred.write(line)\n",
    "        line = \"the man had just bitten him.\\n\"\n",
    "        pred.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the dog bit the man."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pred = \"pred.txt\"  # Test file argument\n",
    "target_ref = \"ref.txt\"  # MTed file argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1st sentence: the dog bit the man.\n"
     ]
    }
   ],
   "source": [
    "refs = []\n",
    "\n",
    "with open(target_ref) as test:\n",
    "    for line in test: \n",
    "        line = line.lower().strip().split()\n",
    "        line = md.detokenize(line)\n",
    "        line = line.lower()    # optional\n",
    "#         refs.append([line])\n",
    "        refs.append(line)\n",
    "        print\n",
    "print(\"Reference 1st sentence:\", refs[0])\n",
    "\n",
    "refs = [refs]  # Yes, it is a list of list(s) as required by sacreBLEU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the dog bit the man.', 'it was not unexpected.', 'the man bit him first.']]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTed 1st sentence: the dog bit the man.\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "\n",
    "with open(target_pred) as pred:  \n",
    "    for line in pred: \n",
    "        line = line.lower().strip().split()\n",
    "        line = md.detokenize(line)\n",
    "        line = line.lower()    # optional\n",
    "        preds.append(line)\n",
    "\n",
    "print(\"MTed 1st sentence:\", preds[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the dog bit the man.',\n",
       " \"it wasn't surprising.\",\n",
       " 'the man had just bitten him.']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU:  45.06750632106114\n"
     ]
    }
   ],
   "source": [
    "bleu = sacrebleu.corpus_bleu(preds, refs)\n",
    "print(\"BLEU: \", bleu.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the dog bit the man.',\n",
       " \"it wasn't surprising.\",\n",
       " 'the man had just bitten him.',\n",
       " 'the dog bit the man.',\n",
       " \"it wasn't surprising.\",\n",
       " 'the man had just bitten him.',\n",
       " 'the dog bit the man.',\n",
       " \"it wasn't surprising.\",\n",
       " 'the man had just bitten him.',\n",
       " 'the dog bit the man.',\n",
       " \"it wasn't surprising.\",\n",
       " 'the man had just bitten him.',\n",
       " 'the dog bit the man.',\n",
       " \"it wasn't surprising.\",\n",
       " 'the man had just bitten him.',\n",
       " 'the dog bit the man.',\n",
       " \"it wasn't surprising.\",\n",
       " 'the man had just bitten him.',\n",
       " 'the dog bit the man.',\n",
       " \"it wasn't surprising.\",\n",
       " 'the man had just bitten him.',\n",
       " 'the dog bit the man.',\n",
       " \"it wasn't surprising.\",\n",
       " 'the man had just bitten him.',\n",
       " 'the dog bit the man.',\n",
       " \"it wasn't surprising.\",\n",
       " 'the man had just bitten him.',\n",
       " 'the dog bit the man.',\n",
       " \"it wasn't surprising.\",\n",
       " 'the man had just bitten him.']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the dog bit the man.',\n",
       "  'it was not unexpected.',\n",
       "  'the man bit him first.',\n",
       "  'the dog bit the man.',\n",
       "  'it was not unexpected.',\n",
       "  'the man bit him first.',\n",
       "  'the dog bit the man.',\n",
       "  'it was not unexpected.',\n",
       "  'the man bit him first.',\n",
       "  'the dog bit the man.',\n",
       "  'it was not unexpected.',\n",
       "  'the man bit him first.',\n",
       "  'the dog bit the man.',\n",
       "  'it was not unexpected.',\n",
       "  'the man bit him first.',\n",
       "  'the dog bit the man.',\n",
       "  'it was not unexpected.',\n",
       "  'the man bit him first.',\n",
       "  'the dog bit the man.',\n",
       "  'it was not unexpected.',\n",
       "  'the man bit him first.',\n",
       "  'the dog bit the man.',\n",
       "  'it was not unexpected.',\n",
       "  'the man bit him first.',\n",
       "  'the dog bit the man.',\n",
       "  'it was not unexpected.',\n",
       "  'the man bit him first.',\n",
       "  'the dog bit the man.',\n",
       "  'it was not unexpected.',\n",
       "  'the man bit him first.']]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[refs[0]*10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU:  45.06750632106114\n"
     ]
    }
   ],
   "source": [
    "bleu = sacrebleu.corpus_bleu(preds, refs)\n",
    "print(\"BLEU: \", bleu.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU:  45.06750632106114\n"
     ]
    }
   ],
   "source": [
    "bleu = sacrebleu.corpus_bleu(preds*1000000, [refs[0]*1000000])\n",
    "print(\"BLEU: \", bleu.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.06750632106114\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "refs = [['The dog bit the man.', 'It was not unexpected.', 'The man bit him first.']]\n",
    "sys = ['The dog bit the man.', \"It wasn't surprising.\", 'The man had just bitten him.']\n",
    "bleu = sacrebleu.corpus_bleu(sys, refs)\n",
    "print(bleu.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_references = refs\n",
    "hypotheses = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['the',\n",
       "   'dog',\n",
       "   'bit',\n",
       "   'the',\n",
       "   'man.',\n",
       "   'it',\n",
       "   'was',\n",
       "   'not',\n",
       "   'unexpected.',\n",
       "   'the',\n",
       "   'man',\n",
       "   'bit',\n",
       "   'him',\n",
       "   'first.'],\n",
       "  ['the',\n",
       "   'dog',\n",
       "   'had',\n",
       "   'bit',\n",
       "   'the',\n",
       "   'man.',\n",
       "   'no',\n",
       "   'one',\n",
       "   'was',\n",
       "   'surprised.',\n",
       "   'the',\n",
       "   'man',\n",
       "   'had',\n",
       "   'bitten',\n",
       "   'the',\n",
       "   'dog.']]]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the',\n",
       "  'dog',\n",
       "  'bit',\n",
       "  'the',\n",
       "  'man.',\n",
       "  'it',\n",
       "  \"wasn't\",\n",
       "  'surprising.',\n",
       "  'the',\n",
       "  'man',\n",
       "  'had',\n",
       "  'just',\n",
       "  'bitten',\n",
       "  'him.']]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.translate.bleu_score.corpus_bleu(list_of_references, hypotheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = [\n",
    "    'The dog bit the man.',\n",
    "    'It was not unexpected.',\n",
    "    'The man bit him first.'\n",
    "]\n",
    "\n",
    "hypothesis = [\n",
    "    'The dog bit the man.',\n",
    "    \"It wasn't surprising.\",\n",
    "    \"The man had just bitten him.\"\n",
    "]\n",
    "\n",
    "hypothesis_tokens = [ \" \".join(line.split(' ')) for line in hypothesis]\n",
    "references_tokens = [[\" \".join(line.split(' '))] for line in references]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'dog', 'bit', 'the', 'man.']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis[0].split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'dog', 'bit', 'the', 'man', '.']\n",
      "The dog bit the man .\n",
      "['It', 'was', \"n't\", 'surprising', '.']\n",
      "It was n't surprising .\n",
      "['The', 'man', 'had', 'just', 'bitten', 'him', '.']\n",
      "The man had just bitten him .\n"
     ]
    }
   ],
   "source": [
    "for i in hypothesis:\n",
    "    print(word_tokenize(i))\n",
    "    print(\" \".join(word_tokenize(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The dog bit the man.',\n",
       " \"It wasn't surprising.\",\n",
       " 'The man had just bitten him.']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The dog bit the man.'],\n",
       " ['It was not unexpected.'],\n",
       " ['The man bit him first.']]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 43.990488\n"
     ]
    }
   ],
   "source": [
    "references = [\n",
    "    'The dog bit the man.',\n",
    "    'It was not unexpected.',\n",
    "    'The man bit him first.'\n",
    "]\n",
    "\n",
    "hypothesis = [\n",
    "    'The dog bit the man.',\n",
    "    \"It wasn't surprising.\",\n",
    "    \"The man had just bitten him.\"\n",
    "]\n",
    "\n",
    "# hypothesis_tokens = [mt.tokenize(line) for line in hypothesis]\n",
    "# references_tokens = [[mt.tokenize(line)] for line in references]\n",
    "\n",
    "hypothesis_tokens = [word_tokenize(line) for line in hypothesis]\n",
    "references_tokens = [[word_tokenize(line)] for line in references]\n",
    "\n",
    "# calculate corpus-bleu score\n",
    "bleu = corpus_bleu(\n",
    "    references_tokens, hypothesis_tokens\n",
    ")\n",
    "\n",
    "print('BLEU: %f' % (bleu * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dog bit the man .\n",
      "It was n't surprising .\n",
      "The man had just bitten him .\n"
     ]
    }
   ],
   "source": [
    "for i in hypothesis_tokens:\n",
    "    print(\" \".join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['The', 'dog', 'bit', 'the', 'man', '.']],\n",
       " [['It', 'was', 'not', 'unexpected', '.']],\n",
       " [['The', 'man', 'bit', 'him', 'first', '.']]]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dog bit the man .\n",
      "It was not unexpected .\n",
      "The man bit him first .\n"
     ]
    }
   ],
   "source": [
    "for i in references_tokens:\n",
    "    print(\" \".join(i[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = sacrebleu.corpus_bleu(sys, refs)\n",
    "print(bleu.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_tokens = [line.split(' ') for line in hypothesis]\n",
    "references_tokens = [[line.split(' ')] for line in references]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Teo', 'S', 'yb', ',', 'oe', 'uNb', ',', 'R', ',', 'T', 't', ',', ',', 't'],\n",
       " ['Tue',\n",
       "  'Ar',\n",
       "  'saln',\n",
       "  'S',\n",
       "  ',',\n",
       "  ',',\n",
       "  '5istsi',\n",
       "  'l',\n",
       "  ',',\n",
       "  '5oe',\n",
       "  'R',\n",
       "  'ulO',\n",
       "  'sae',\n",
       "  'oR',\n",
       "  'R'],\n",
       " ['Teo', 'S', 'yb', ',', 'oe', 'uNb', ',', 'R', ',', 'T', 't', ',', ',', 't'],\n",
       " ['Tue',\n",
       "  'Ar',\n",
       "  'saln',\n",
       "  'S',\n",
       "  ',',\n",
       "  ',',\n",
       "  '5istsi',\n",
       "  'l',\n",
       "  ',',\n",
       "  '5oe',\n",
       "  'R',\n",
       "  'ulO',\n",
       "  'sae',\n",
       "  'oR',\n",
       "  'R'],\n",
       " ['Teo', 'S', 'yb', ',', 'oe', 'uNb', ',', 'R', ',', 'T', 't', ',', ',', 't'],\n",
       " ['Tue',\n",
       "  'Ar',\n",
       "  'saln',\n",
       "  'S',\n",
       "  ',',\n",
       "  ',',\n",
       "  '5istsi',\n",
       "  'l',\n",
       "  ',',\n",
       "  '5oe',\n",
       "  'R',\n",
       "  'ulO',\n",
       "  'sae',\n",
       "  'oR',\n",
       "  'R'],\n",
       " ['Teo', 'S', 'yb', ',', 'oe', 'uNb', ',', 'R', ',', 'T', 't', ',', ',', 't'],\n",
       " ['Tue',\n",
       "  'Ar',\n",
       "  'saln',\n",
       "  'S',\n",
       "  ',',\n",
       "  ',',\n",
       "  '5istsi',\n",
       "  'l',\n",
       "  ',',\n",
       "  '5oe',\n",
       "  'R',\n",
       "  'ulO',\n",
       "  'sae',\n",
       "  'oR',\n",
       "  'R'],\n",
       " ['Teo', 'S', 'yb', ',', 'oe', 'uNb', ',', 'R', ',', 'T', 't', ',', ',', 't'],\n",
       " ['Tue',\n",
       "  'Ar',\n",
       "  'saln',\n",
       "  'S',\n",
       "  ',',\n",
       "  ',',\n",
       "  '5istsi',\n",
       "  'l',\n",
       "  ',',\n",
       "  '5oe',\n",
       "  'R',\n",
       "  'ulO',\n",
       "  'sae',\n",
       "  'oR',\n",
       "  'R']]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Their',\n",
       "   'tasks',\n",
       "   'include',\n",
       "   'changing',\n",
       "   'a',\n",
       "   'pump',\n",
       "   'on',\n",
       "   'the',\n",
       "   'faulty',\n",
       "   'stokehold',\n",
       "   '.']],\n",
       " [['Likewise',\n",
       "   ',',\n",
       "   'two',\n",
       "   'species',\n",
       "   'that',\n",
       "   'are',\n",
       "   'very',\n",
       "   'similar',\n",
       "   'in',\n",
       "   'morphology',\n",
       "   'were',\n",
       "   'distinguished',\n",
       "   'using',\n",
       "   'genetics',\n",
       "   '.']],\n",
       " [['Their',\n",
       "   'tasks',\n",
       "   'include',\n",
       "   'changing',\n",
       "   'a',\n",
       "   'pump',\n",
       "   'on',\n",
       "   'the',\n",
       "   'faulty',\n",
       "   'stokehold',\n",
       "   '.']],\n",
       " [['Likewise',\n",
       "   ',',\n",
       "   'two',\n",
       "   'species',\n",
       "   'that',\n",
       "   'are',\n",
       "   'very',\n",
       "   'similar',\n",
       "   'in',\n",
       "   'morphology',\n",
       "   'were',\n",
       "   'distinguished',\n",
       "   'using',\n",
       "   'genetics',\n",
       "   '.']],\n",
       " [['Their',\n",
       "   'tasks',\n",
       "   'include',\n",
       "   'changing',\n",
       "   'a',\n",
       "   'pump',\n",
       "   'on',\n",
       "   'the',\n",
       "   'faulty',\n",
       "   'stokehold',\n",
       "   '.']],\n",
       " [['Likewise',\n",
       "   ',',\n",
       "   'two',\n",
       "   'species',\n",
       "   'that',\n",
       "   'are',\n",
       "   'very',\n",
       "   'similar',\n",
       "   'in',\n",
       "   'morphology',\n",
       "   'were',\n",
       "   'distinguished',\n",
       "   'using',\n",
       "   'genetics',\n",
       "   '.']],\n",
       " [['Their',\n",
       "   'tasks',\n",
       "   'include',\n",
       "   'changing',\n",
       "   'a',\n",
       "   'pump',\n",
       "   'on',\n",
       "   'the',\n",
       "   'faulty',\n",
       "   'stokehold',\n",
       "   '.']],\n",
       " [['Likewise',\n",
       "   ',',\n",
       "   'two',\n",
       "   'species',\n",
       "   'that',\n",
       "   'are',\n",
       "   'very',\n",
       "   'similar',\n",
       "   'in',\n",
       "   'morphology',\n",
       "   'were',\n",
       "   'distinguished',\n",
       "   'using',\n",
       "   'genetics',\n",
       "   '.']],\n",
       " [['Their',\n",
       "   'tasks',\n",
       "   'include',\n",
       "   'changing',\n",
       "   'a',\n",
       "   'pump',\n",
       "   'on',\n",
       "   'the',\n",
       "   'faulty',\n",
       "   'stokehold',\n",
       "   '.']],\n",
       " [['Likewise',\n",
       "   ',',\n",
       "   'two',\n",
       "   'species',\n",
       "   'that',\n",
       "   'are',\n",
       "   'very',\n",
       "   'similar',\n",
       "   'in',\n",
       "   'morphology',\n",
       "   'were',\n",
       "   'distinguished',\n",
       "   'using',\n",
       "   'genetics',\n",
       "   '.']]]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-598fad6f0105>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# calculate corpus-bleu score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m bleu = corpus_bleu(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mreferences_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py\u001b[0m in \u001b[0;36mcorpus_bleu\u001b[0;34m(list_of_references, hypotheses, weights, smoothing_function, auto_reweigh)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# denominator for the corpus-level modified precision.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mp_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodified_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0mp_numerators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mp_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mp_denominators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mp_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdenominator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/translate/bleu_score.py\u001b[0m in \u001b[0;36mmodified_precision\u001b[0;34m(references, hypothesis, n)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mreference\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         reference_counts = (\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         )\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/collections/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expected at most 1 arguments, got %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/collections/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    639\u001b[0m                             \"needs an argument\")\n\u001b[1;32m    640\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expected at most 1 arguments, got %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0miterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# calculate corpus-bleu score\n",
    "bleu = corpus_bleu(\n",
    "    references_tokens, hypothesis_tokens\n",
    ")\n",
    "\n",
    "print('BLEU: %f' % (bleu * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
