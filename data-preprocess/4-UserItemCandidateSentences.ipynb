{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sw/centos/anaconda3/2019.10/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "# Create a Tokenizer with the default settings for English\n",
    "# including punctuation rules and exceptions\n",
    "tokenizer = nlp.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "punct = string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 lines loaded.\n",
      "200000 lines loaded.\n",
      "300000 lines loaded.\n",
      "Finish loading train dataset, totally 302573 lines.\n",
      "10000 lines loaded.\n",
      "20000 lines loaded.\n",
      "30000 lines loaded.\n",
      "40000 lines loaded.\n",
      "Finish loading test dataset, totally 40730 lines.\n"
     ]
    }
   ],
   "source": [
    "dir_path = '../Dataset/ratebeer/large_500'\n",
    "# Load train dataset\n",
    "train_review = []\n",
    "cnt = 0\n",
    "file_path = os.path.join(dir_path, 'train_review_filtered.json')\n",
    "with open(file_path) as f:\n",
    "    for line in f:\n",
    "        line_data = json.loads(line)\n",
    "        user_id = line_data['user']\n",
    "        item_id = line_data['item']\n",
    "        rating = line_data['rating']\n",
    "        review = line_data['review']\n",
    "        train_review.append([item_id, user_id, rating, review])\n",
    "        cnt += 1\n",
    "        if cnt % 100000 == 0:\n",
    "            print('{} lines loaded.'.format(cnt))\n",
    "print('Finish loading train dataset, totally {} lines.'.format(len(train_review)))\n",
    "# Load test dataset\n",
    "test_review = []\n",
    "cnt = 0\n",
    "file_path = os.path.join(dir_path, 'test_review_filtered.json')\n",
    "with open(file_path) as f:\n",
    "    for line in f:\n",
    "        line_data = json.loads(line)\n",
    "        user_id = line_data['user']\n",
    "        item_id = line_data['item']\n",
    "        rating = line_data['rating']\n",
    "        review = line_data['review']\n",
    "        test_review.append([item_id, user_id, rating, review])\n",
    "        cnt += 1\n",
    "        if cnt % 10000 == 0:\n",
    "            print('{} lines loaded.'.format(cnt))\n",
    "print('Finish loading test dataset, totally {} lines.'.format(len(test_review)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_data = pd.DataFrame(train_review, columns=['item', 'user', 'rating', 'review'])\n",
    "df_test_data = pd.DataFrame(test_review, columns=['item', 'user', 'rating', 'review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item</th>\n      <th>user</th>\n      <th>rating</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>196</td>\n      <td>999</td>\n      <td>17</td>\n      <td>dark brown body with a light brown head . nutt...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1149</td>\n      <td>999</td>\n      <td>14</td>\n      <td>hazy orange / gold body is topped by a medium ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>236</td>\n      <td>999</td>\n      <td>16</td>\n      <td>12 oz bottle thanks to acknud . pours much dar...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>634</td>\n      <td>999</td>\n      <td>15</td>\n      <td>clear and radiant mahogany body with a small b...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>490</td>\n      <td>999</td>\n      <td>16</td>\n      <td>nice looker with tons of spiderweb lacing . bo...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>302568</th>\n      <td>373</td>\n      <td>3849</td>\n      <td>9</td>\n      <td>this shit is rejected coors light , i m certai...</td>\n    </tr>\n    <tr>\n      <th>302569</th>\n      <td>1458</td>\n      <td>3849</td>\n      <td>10</td>\n      <td>being a philly fan , i m supposed to hate anyt...</td>\n    </tr>\n    <tr>\n      <th>302570</th>\n      <td>269</td>\n      <td>3849</td>\n      <td>10</td>\n      <td>a good malt liquor , undeniably , but it was l...</td>\n    </tr>\n    <tr>\n      <th>302571</th>\n      <td>859</td>\n      <td>3849</td>\n      <td>2</td>\n      <td>how this beer is actually better than regular ...</td>\n    </tr>\n    <tr>\n      <th>302572</th>\n      <td>779</td>\n      <td>3849</td>\n      <td>3</td>\n      <td>slightly better than the beast , but damn , ho...</td>\n    </tr>\n  </tbody>\n</table>\n<p>302573 rows × 4 columns</p>\n</div>",
      "text/plain": "        item  user  rating                                             review\n0        196   999      17  dark brown body with a light brown head . nutt...\n1       1149   999      14  hazy orange / gold body is topped by a medium ...\n2        236   999      16  12 oz bottle thanks to acknud . pours much dar...\n3        634   999      15  clear and radiant mahogany body with a small b...\n4        490   999      16  nice looker with tons of spiderweb lacing . bo...\n...      ...   ...     ...                                                ...\n302568   373  3849       9  this shit is rejected coors light , i m certai...\n302569  1458  3849      10  being a philly fan , i m supposed to hate anyt...\n302570   269  3849      10  a good malt liquor , undeniably , but it was l...\n302571   859  3849       2  how this beer is actually better than regular ...\n302572   779  3849       3  slightly better than the beast , but damn , ho...\n\n[302573 rows x 4 columns]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 data instance are the same\n"
     ]
    }
   ],
   "source": [
    "# groupby multiple columns\n",
    "groupby_user_item = df_train_data.groupby(['user', 'item'])\n",
    "cnt = 0\n",
    "for key, item in groupby_user_item:\n",
    "    cur_df_user_item = groupby_user_item.get_group(key)\n",
    "    if len(cur_df_user_item) > 1:\n",
    "        if cnt <= 10:\n",
    "            print(cur_df_user_item)\n",
    "        cnt += 1\n",
    "print(\"{} data instance are the same\".format(cnt))\n",
    "# make sure that there are no duplicated reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sentence2ID and ID2Sentence Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Dataset/ratebeer/large_500/train/sentence/sentence2id.json', 'r') as f:\n",
    "    sent_to_id = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "str"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sent_to_id['bottle at home .'])\n",
    "# id are stored as str (not int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Dataset/ratebeer/large_500/train/sentence/id2sentence.json', 'r') as f:\n",
    "    id_to_sent = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'bottle at home .'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_sent['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent_to_id) == len(id_to_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1246458"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Feature Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_2_id_file = '../Dataset/ratebeer/large_500/train/feature/feature2id.json'\n",
    "with open(feature_2_id_file, 'r') as f:\n",
    "    feature_vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2000"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'1'"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vocab['aroma']\n",
    "# feature id is stored as str (not int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sentence2Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Dataset/ratebeer/large_500/train/sentence/sentence2feature.json', 'r') as f:\n",
    "    sentence_to_feature = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'10': 0.4639189217945095, '486': 0.8858776631121363}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_to_feature['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1246458"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert len(sentence_to_feature) == len(sent_to_id)\n",
    "len(sentence_to_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct User-Item Pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBy User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_user = df_train_data.groupby('user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_user_dict = dict(tuple(group_by_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item</th>\n      <th>user</th>\n      <th>rating</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>55001</th>\n      <td>222</td>\n      <td>1223</td>\n      <td>11</td>\n      <td>lo mismo que el aleman , esperaba mas bottle :...</td>\n    </tr>\n    <tr>\n      <th>55002</th>\n      <td>923</td>\n      <td>1223</td>\n      <td>1</td>\n      <td>tipica cerveza latina que hay que tomarse rapi...</td>\n    </tr>\n    <tr>\n      <th>55003</th>\n      <td>1078</td>\n      <td>1223</td>\n      <td>12</td>\n      <td>para ser un pale ale normal , bastante mejor q...</td>\n    </tr>\n    <tr>\n      <th>55004</th>\n      <td>987</td>\n      <td>1223</td>\n      <td>1</td>\n      <td>this beer gives me so much gas that i had to m...</td>\n    </tr>\n    <tr>\n      <th>55005</th>\n      <td>1055</td>\n      <td>1223</td>\n      <td>15</td>\n      <td>la birria parecida , salada y hoppy</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>55089</th>\n      <td>849</td>\n      <td>1223</td>\n      <td>13</td>\n      <td>imperial stouts are the shiznit . every day i ...</td>\n    </tr>\n    <tr>\n      <th>55090</th>\n      <td>1148</td>\n      <td>1223</td>\n      <td>12</td>\n      <td>en pike brewery con sici , parte de un sampler...</td>\n    </tr>\n    <tr>\n      <th>55091</th>\n      <td>2275</td>\n      <td>1223</td>\n      <td>14</td>\n      <td>bastante hoppy</td>\n    </tr>\n    <tr>\n      <th>55092</th>\n      <td>494</td>\n      <td>1223</td>\n      <td>12</td>\n      <td>solo es black &lt; , no muy ale ni cigar . intrer...</td>\n    </tr>\n    <tr>\n      <th>55093</th>\n      <td>756</td>\n      <td>1223</td>\n      <td>12</td>\n      <td>interesante birria con sabor a summer ale y un...</td>\n    </tr>\n  </tbody>\n</table>\n<p>93 rows × 4 columns</p>\n</div>",
      "text/plain": "       item  user  rating                                             review\n55001   222  1223      11  lo mismo que el aleman , esperaba mas bottle :...\n55002   923  1223       1  tipica cerveza latina que hay que tomarse rapi...\n55003  1078  1223      12  para ser un pale ale normal , bastante mejor q...\n55004   987  1223       1  this beer gives me so much gas that i had to m...\n55005  1055  1223      15                la birria parecida , salada y hoppy\n...     ...   ...     ...                                                ...\n55089   849  1223      13  imperial stouts are the shiznit . every day i ...\n55090  1148  1223      12  en pike brewery con sici , parte de un sampler...\n55091  2275  1223      14                                     bastante hoppy\n55092   494  1223      12  solo es black < , no muy ale ni cigar . intrer...\n55093   756  1223      12  interesante birria con sabor a summer ale y un...\n\n[93 rows x 4 columns]"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_by_user_dict['1223']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2963"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(group_by_user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_list = list(df_train_data['user'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2963\n"
     ]
    }
   ],
   "source": [
    "print(len(user_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 sentence with no feature\n"
     ]
    }
   ],
   "source": [
    "user_to_sent = dict()\n",
    "cnt_sentence_with_no_feature = 0\n",
    "\n",
    "for user_id in user_id_list:\n",
    "    # note this user_id is a str\n",
    "    # get the dataframe for this user\n",
    "    user_df = group_by_user_dict[user_id]\n",
    "    user_reviews = list(user_df['review'])\n",
    "    user_sent_ids = set()\n",
    "    for review in user_reviews:\n",
    "        # tokenize this review (i.e. split into sentences)\n",
    "        review_sents = sent_tokenize(review)\n",
    "        # check whether the sentence is in the sentence2id dictionary\n",
    "        for sent in review_sents:\n",
    "            if sent in sent_to_id:\n",
    "                cur_sent_id = sent_to_id[sent]\n",
    "                assert isinstance(cur_sent_id, str)\n",
    "                # make sure that this sentence has feature\n",
    "                # assert cur_sent_id in sentence_to_feature\n",
    "                # user_sent_ids.add(cur_sent_id)\n",
    "                if cur_sent_id in sentence_to_feature:\n",
    "                    # add this sentence into the set of this user\n",
    "                    user_sent_ids.add(cur_sent_id)\n",
    "                else:\n",
    "                    cnt_sentence_with_no_feature += 1\n",
    "        # TODO: what should we do if there are sentence that appears in multiple reivews?\n",
    "    user_to_sent[user_id] = user_sent_ids\n",
    "print('{} sentence with no feature'.format(cnt_sentence_with_no_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2963"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_to_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_sentids = dict()\n",
    "for user_id, user_sents in user_to_sent.items():\n",
    "    assert len(user_sents) > 0\n",
    "    assert isinstance(user_id, str)\n",
    "    assert isinstance(list(user_sents)[0], str)\n",
    "    user_to_sentids[user_id] = list(user_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2963"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_to_sentids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Dataset/ratebeer/large_500/train/user/user2sentids.json', 'w') as f:\n",
    "    json.dump(user_to_sentids, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBy Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_item = df_train_data.groupby('item')\n",
    "group_by_item_dict = dict(tuple(group_by_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item</th>\n      <th>user</th>\n      <th>rating</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>136</th>\n      <td>256</td>\n      <td>999</td>\n      <td>15</td>\n      <td>12 oz bottle pours a hazy copper body topped b...</td>\n    </tr>\n    <tr>\n      <th>1968</th>\n      <td>256</td>\n      <td>1892</td>\n      <td>14</td>\n      <td>on tap @ the \" sarasota rhythm &amp; brews festiva...</td>\n    </tr>\n    <tr>\n      <th>2794</th>\n      <td>256</td>\n      <td>677</td>\n      <td>15</td>\n      <td>hazy copper pour with a creamy head . the nose...</td>\n    </tr>\n    <tr>\n      <th>4028</th>\n      <td>256</td>\n      <td>610</td>\n      <td>12</td>\n      <td>a decent flavored pale ale but not much body t...</td>\n    </tr>\n    <tr>\n      <th>4542</th>\n      <td>256</td>\n      <td>1381</td>\n      <td>15</td>\n      <td>deep gold color with hints of orange and a whi...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>298708</th>\n      <td>256</td>\n      <td>2648</td>\n      <td>14</td>\n      <td>bottle . copper / amber pour with white head ....</td>\n    </tr>\n    <tr>\n      <th>298720</th>\n      <td>256</td>\n      <td>3356</td>\n      <td>13</td>\n      <td>aroma : roasted grain , fruity - - pear , peac...</td>\n    </tr>\n    <tr>\n      <th>300472</th>\n      <td>256</td>\n      <td>3380</td>\n      <td>10</td>\n      <td>a little skunk aroma when opened , nice color ...</td>\n    </tr>\n    <tr>\n      <th>301398</th>\n      <td>256</td>\n      <td>2605</td>\n      <td>15</td>\n      <td>a good pale ale . it has a nice light malt aro...</td>\n    </tr>\n    <tr>\n      <th>301693</th>\n      <td>256</td>\n      <td>2237</td>\n      <td>12</td>\n      <td>lots of colour in this one . sweet hop aroma ....</td>\n    </tr>\n  </tbody>\n</table>\n<p>355 rows × 4 columns</p>\n</div>",
      "text/plain": "       item  user  rating                                             review\n136     256   999      15  12 oz bottle pours a hazy copper body topped b...\n1968    256  1892      14  on tap @ the \" sarasota rhythm & brews festiva...\n2794    256   677      15  hazy copper pour with a creamy head . the nose...\n4028    256   610      12  a decent flavored pale ale but not much body t...\n4542    256  1381      15  deep gold color with hints of orange and a whi...\n...     ...   ...     ...                                                ...\n298708  256  2648      14  bottle . copper / amber pour with white head ....\n298720  256  3356      13  aroma : roasted grain , fruity - - pear , peac...\n300472  256  3380      10  a little skunk aroma when opened , nice color ...\n301398  256  2605      15  a good pale ale . it has a nice light malt aro...\n301693  256  2237      12  lots of colour in this one . sweet hop aroma ....\n\n[355 rows x 4 columns]"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_by_item_dict['256']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "3744"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(group_by_item_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 sentence with no feature\n"
     ]
    }
   ],
   "source": [
    "item_id_list = list(df_train_data['item'].unique())\n",
    "item_to_sent = dict()\n",
    "cnt_sentence_with_no_feature = 0\n",
    "for item_id in item_id_list:\n",
    "    # note this item_id is a str\n",
    "    # get the dataframe for this item\n",
    "    assert isinstance(item_id, str)\n",
    "    item_df = group_by_item_dict[item_id]\n",
    "    item_reviews = list(item_df['review'])\n",
    "    item_sent_ids = set()\n",
    "    for review in item_reviews:\n",
    "        # tokenize this review (i.e. split into sentences)\n",
    "        review_sents = sent_tokenize(review)\n",
    "        # check whether the sentence is in the sentence2id dictionary\n",
    "        for sent in review_sents:\n",
    "            if sent in sent_to_id:\n",
    "                cur_sent_id = sent_to_id[sent]\n",
    "                assert isinstance(cur_sent_id, str)\n",
    "                # make sure that this sentence has feature\n",
    "                if cur_sent_id in sentence_to_feature:\n",
    "                    # add this sentence into the set of this user\n",
    "                    item_sent_ids.add(cur_sent_id)\n",
    "                else:\n",
    "                    cnt_sentence_with_no_feature += 1\n",
    "        # TODO: what should we do if there are sentence that appears in multiple reivews?\n",
    "    item_to_sent[item_id] = item_sent_ids\n",
    "\n",
    "print('{} sentence with no feature'.format(cnt_sentence_with_no_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "3744"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(item_to_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_to_sentids = dict()\n",
    "for item_id, item_sents in item_to_sent.items():\n",
    "    assert len(item_sents) > 0\n",
    "    assert isinstance(list(item_sents)[0], str)\n",
    "    item_to_sentids[item_id] = list(item_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "3744"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(item_to_sentids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Dataset/ratebeer/large_500/train/item/item2sentids.json', 'w') as f:\n",
    "    json.dump(item_to_sentids, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Each Data Instance in Trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 user processed\n",
      "400 user processed\n",
      "600 user processed\n",
      "800 user processed\n",
      "1000 user processed\n",
      "1200 user processed\n",
      "1400 user processed\n",
      "1600 user processed\n",
      "1800 user processed\n",
      "2000 user processed\n",
      "2200 user processed\n",
      "2400 user processed\n",
      "2600 user processed\n",
      "2800 user processed\n",
      "Finish.\n",
      "Totally 2963 users\n",
      "Totally 302573 reviews. Among them 234 reviews has empty true label sentence\n",
      "0 sentences has 0 feature\n",
      "14774 sentences are not being tracked in the sent2id mapping\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "sample_sent_num = 500\n",
    "user_item_candidate_sent_ids = dict()\n",
    "# Loop over all User\n",
    "user_cnt = 0\n",
    "review_cnt = 0\n",
    "review_with_no_selectd_label_sentence = 0\n",
    "useable_review_cnt = 0\n",
    "sentence_with_no_feature_cnt = 0\n",
    "sentence_not_tracked = set()\n",
    "for user_df_chunk in list(group_by_user):\n",
    "    user_id = int(user_df_chunk[0])\n",
    "    user_id_str = str(user_df_chunk[0])\n",
    "    user_df = user_df_chunk[1]\n",
    "    # get user sents\n",
    "    cur_user_sent_ids = user_to_sent[user_id_str]\n",
    "    # item-level dict\n",
    "    item_candidate_sent_ids = dict()\n",
    "    for idx, row in user_df.iterrows():\n",
    "        item_id = int(row['item'])\n",
    "        item_id_str = str(row['item'])\n",
    "        review_text = row['review']\n",
    "        review_cnt += 1\n",
    "        # get item sents\n",
    "        cur_item_sent_ids = item_to_sent[item_id_str]\n",
    "        # get review_text's sent ids\n",
    "        cur_review_sent_ids = set()\n",
    "        ## tokenize this review\n",
    "        review_sents = sent_tokenize(review_text)\n",
    "        ## check whether this sentence is in the sentence2id dictionary\n",
    "        for sent in review_sents:\n",
    "            if sent in sent_to_id:\n",
    "                cur_sent_id = sent_to_id[sent]\n",
    "                assert isinstance(cur_sent_id, str)\n",
    "                # make sure that this sentence has feature\n",
    "                if cur_sent_id in sentence_to_feature:\n",
    "                    # add this sentence into the set of current review\n",
    "                    cur_review_sent_ids.add(cur_sent_id)\n",
    "                else:\n",
    "                    sentence_with_no_feature_cnt += 1\n",
    "            else:\n",
    "                # if this sentence is not being tracked by the sentence-id mapping\n",
    "                # we add it into this set to see how many sentences are being ignored\n",
    "                sentence_not_tracked.add(sent)\n",
    "        ## check whether the true label of the sentence is an empty list of sent_ids\n",
    "        if len(cur_review_sent_ids) == 0:\n",
    "            review_with_no_selectd_label_sentence += 1\n",
    "        else:\n",
    "            # construct the candidate set which is an union of user sentences and item sentences\n",
    "            cur_useritem_sent_ids = cur_user_sent_ids | cur_item_sent_ids\n",
    "            # sample some sentences\n",
    "            if len(cur_useritem_sent_ids) > sample_sent_num:\n",
    "                sample_useritem_sent_ids = set(random.sample(cur_useritem_sent_ids, sample_sent_num))\n",
    "            else:\n",
    "                # FIXED: \n",
    "                # IMPORTANT: Here is a bug!!!\n",
    "                # sample_useritem_sent_ids = cur_user_sent_ids\n",
    "                sample_useritem_sent_ids = cur_useritem_sent_ids\n",
    "            # union sampled sentences with true labeled sentences\n",
    "            final_useritem_sent_ids = sample_useritem_sent_ids | cur_review_sent_ids\n",
    "            # add this into the dict\n",
    "            item_candidate_sent_ids[item_id_str] = [list(final_useritem_sent_ids), list(cur_review_sent_ids)]\n",
    "            # add useable review cnt\n",
    "            useable_review_cnt += 1\n",
    "    # add the item_candidate_sent_ids dict into the user-level dict\n",
    "    user_item_candidate_sent_ids[user_id_str] = item_candidate_sent_ids\n",
    "    user_cnt += 1\n",
    "    if user_cnt % 200 == 0:\n",
    "        print(\"{} user processed\".format(user_cnt))\n",
    "\n",
    "print('Finish.')\n",
    "print('Totally {} users'.format(user_cnt))\n",
    "print('Totally {0} reviews. Among them {1} reviews has empty true label sentence'.format(\n",
    "    review_cnt, review_with_no_selectd_label_sentence))\n",
    "print(\"{} sentences has 0 feature\".format(sentence_with_no_feature_cnt))\n",
    "print(\"{} sentences are not being tracked in the sent2id mapping\".format(len(sentence_not_tracked)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2963"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_item_candidate_sent_ids)\n",
    "# there are 2968 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique selected reviews: 302339\n",
      "Total number of review with empty true sentences: 0\n",
      "Total number of unique review with non-empty true sentences: 302339\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Since there are still some duplicated reviews\n",
    "# let's check how many unique reviews are there\n",
    "\n",
    "cnt_unique_reviews = 0\n",
    "cnt_empty_true_sent = 0\n",
    "sentence_per_review = []\n",
    "# [user-level] Loop for each user\n",
    "for user_chunk in list(user_item_candidate_sent_ids.items()):\n",
    "    user_id_str = str(user_chunk[0])\n",
    "    # assert isinstance(user_chunk[0], str)\n",
    "    # [item-level] Loop for each user-item pair\n",
    "    user_item_chunks = list(user_chunk[1].items())\n",
    "    for item_chunk in user_item_chunks:\n",
    "        item_id_str = str(item_chunk[0])\n",
    "        # assert isinstance(item_chunk[0], str)\n",
    "        candidate_sent_ids = item_chunk[1][0]\n",
    "        true_sent_ids = item_chunk[1][1]\n",
    "        if len(true_sent_ids) == 0:\n",
    "            cnt_empty_true_sent += 1\n",
    "        else:\n",
    "            assert isinstance(candidate_sent_ids[0], str)\n",
    "            assert isinstance(true_sent_ids[0], str)\n",
    "            sentence_per_review.append(len(true_sent_ids))\n",
    "        cnt_unique_reviews += 1\n",
    "\n",
    "print(\"Total number of unique selected reviews: {}\".format(cnt_unique_reviews))\n",
    "print(\"Total number of review with empty true sentences: {}\".format(cnt_empty_true_sent))\n",
    "print(\"Total number of unique review with non-empty true sentences: {}\".format(\n",
    "    cnt_unique_reviews - cnt_empty_true_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 302339 user-item pairs in the trainset\n",
      "max number of true sentence per review: 48\n",
      "min number of true sentence per review: 1\n",
      "mean number of true sentence per review: 4.417336169002345\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Totally {} user-item pairs in the trainset\".format(len(sentence_per_review)))\n",
    "print(\"max number of true sentence per review: {}\".format(np.max(sentence_per_review)))\n",
    "print(\"min number of true sentence per review: {}\".format(np.min(sentence_per_review)))\n",
    "print(\"mean number of true sentence per review: {}\".format(np.mean(sentence_per_review)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Dataset/ratebeer/large_500/train/useritem2sentids.json', 'w') as f:\n",
    "    json.dump(user_item_candidate_sent_ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "503"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_item_candidate_sent_ids['1892']['256'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "308"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_to_sent['1892'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1510"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(item_to_sent['256'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1813"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(user_to_sent['1892']) | set(item_to_sent['256']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "5"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_item_candidate_sent_ids['1892']['256'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('2019.10': virtualenv)",
   "name": "python374jvsc74a57bd020bbdedb0079e23a85211f14a09dbcc829fefc965ff02508ebf68fe08b48d387"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "20bbdedb0079e23a85211f14a09dbcc829fefc965ff02508ebf68fe08b48d387"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}