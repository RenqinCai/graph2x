{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "!which python"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "/u/pw7nc/anaconda3/bin/python\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "from numpy.lib.npyio import load\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "import os\n",
                "import numpy as np\n",
                "from sklearn import metrics\n",
                "import json"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "def readJson(fname):\n",
                "    data = []\n",
                "    line_num = 0\n",
                "    with open(fname, encoding=\"utf-8\") as f:\n",
                "        for line in f:\n",
                "            # print(\"line\", line)\n",
                "            line_num += 1\n",
                "            try:\n",
                "                data.append(json.loads(line))\n",
                "            except:\n",
                "                print(\"error\", line_num)\n",
                "    return data"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "def load_train_feature_label(feature_label_file):\n",
                "    x = []\n",
                "    y = []\n",
                "    user_item_pair = []\n",
                "\n",
                "    with open(feature_label_file, \"r\") as f:\n",
                "        for raw_line in f:\n",
                "            line_data = json.loads(raw_line)\n",
                "            assert len(line_data['f_hidden']) == 257\n",
                "            x.append(line_data['f_hidden'][:-1])\n",
                "            y.append(line_data['f_hidden'][-1])\n",
                "\n",
                "    x = np.array(x)\n",
                "    y = np.array(y)\n",
                "    print(\"x size\", x.shape)\n",
                "    print(\"y size\", y.shape)\n",
                "\n",
                "    return x, y"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "train_input_file = \"../../result/feature_purify/lr0.0005_06_22/feature_lambda_0.0/origin_train/train_f_hidden.json\"\n",
                "train_x, train_y = load_train_feature_label(train_input_file)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "x size (24010, 256)\n",
                        "y size (24010,)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "source": [
                "def load_test_feature_label(feature_label_file):\n",
                "    x = []\n",
                "    y = []\n",
                "    user_item_pair = []\n",
                "\n",
                "    data = readJson(feature_label_file)\n",
                "    data_num = len(data)\n",
                "\n",
                "    # feature ids for each user-item pair. List of 1-dim ndarrays\n",
                "    x_ids = []\n",
                "    # feature hidden embeddings for each feature of each user-item pair.\n",
                "    # List of 2-dim ndarrays\n",
                "    x = []\n",
                "    # gt-feature ids for each user-item pair. List of 1-dim ndarrays\n",
                "    y = []\n",
                "    # we need the number of features in the top-selected sentences so that we can select the top-k features\n",
                "    topk_y = []\n",
                "    for i in range(data_num):\n",
                "        data_i = data[i]\n",
                "        pair_index = data_i['ui_pair_index']\n",
                "        user_item_pair.append(pair_index)\n",
                "        # get the feature ids and hidden embeddings\n",
                "        feature_id_embed = data_i[\"feature\"]\n",
                "        feature_id_embed = np.array(feature_id_embed)\n",
                "        feature_id = feature_id_embed[:, 0]\n",
                "        feature_embed = feature_id_embed[:, 1: ]\n",
                "        x_ids.append(feature_id)\n",
                "        x.append(feature_embed)\n",
                "        # get the number of features in the selected sentences\n",
                "        topk_num = data_i[\"topk\"]\n",
                "        topk_y.append(topk_num)\n",
                "        # get the feature ids in the gt sentences\n",
                "        gt_feature_id = data_i[\"gt\"]\n",
                "        y.append(gt_feature_id)\n",
                "\n",
                "    # x = np.array(x)\n",
                "    # # y = np.array(y)\n",
                "    # print(\"x size\", x.shape)\n",
                "\n",
                "    return x_ids, x, topk_y, y"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "test_input_file = \"../../result/feature_purify/lr0.0005_06_22/feature_lambda_0.0/origin_test/test_f_hidden.json\"\n",
                "test_x_ids, test_x, test_topk_num, test_y = load_test_feature_label(test_input_file)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "source": [
                "len(test_x_ids)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "80"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 16
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "source": [
                "len(test_x_ids[0])"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "294"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 21
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "source": [
                "type(test_x_ids[0])"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "numpy.ndarray"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 30
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "source": [
                "len(test_x)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "80"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 18
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "source": [
                "test_x[0].shape"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "(294, 256)"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 20
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "source": [
                "def train_model(x, y, max_iter):\n",
                "\n",
                "    clf = LogisticRegression(random_state=0, max_iter=max_iter).fit(x, y)\n",
                "    \n",
                "    return clf"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "source": [
                "def iterate_eval_model(model, x_ids, x, y, test_topk_num):\n",
                "    pair_num = len(x)\n",
                "    precision_list = []\n",
                "    recall_list = []\n",
                "    f1_list = []\n",
                "    auc = []\n",
                "\n",
                "    for i in range(pair_num):\n",
                "        x_i = x[i]          # feature hidden embeddings for each feature of each user-item pair.\n",
                "        y_i = y[i]          # gt feature ids for each user-item pair.\n",
                "        xid_i = x_ids[i]    # feature ids (in cdd sents) for each user-item pair.\n",
                "        topk_i = test_topk_num[i]   # number of features in the 3gram selected sentences.\n",
                "\n",
                "        preds_i = model.predict_proba(x_i)      # proba of each feature embedding's label. (n_samples, n_classes=2)\n",
                "        # get the top-k indices of the predict proba of label 1\n",
                "        idx_i = np.argpartition(preds_i[:,1], -topk_i)[-topk_i:]  # Indices not sorted\n",
                "        # sort the indices so that the corresponding predict probas are in an descending order\n",
                "        topk_preds_idx_i = idx_i[np.argsort(preds_i[:,1][idx_i])][::-1] \n",
                "        # get the top-k's corresponding feature ids\n",
                "        topk_preds_i = xid_i[topk_preds_idx_i]\n",
                "        \n",
                "        TP = set(topk_preds_i).intersection(set(y_i))\n",
                "\n",
                "        precision = len(TP)/topk_i\n",
                "        recall = len(TP)/len(y_i)\n",
                "\n",
                "        if (precision+recall) != 0.0:\n",
                "            f1 = 2*precision*recall/(precision+recall)\n",
                "        else:\n",
                "            f1 = 0.0\n",
                "\n",
                "        precision_list.append(precision)\n",
                "        recall_list.append(recall)\n",
                "        f1_list.append(f1)\n",
                "\n",
                "    avg_precision = np.mean(precision_list)\n",
                "    avg_recall = np.mean(recall_list)\n",
                "    avg_f1 = np.mean(f1_list)\n",
                "    \n",
                "    return avg_precision, avg_recall, avg_f1"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "source": [
                "lr_model = train_model(train_x, train_y, max_iter=1000)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "/u/pw7nc/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
                        "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
                        "\n",
                        "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
                        "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
                        "Please also refer to the documentation for alternative solver options:\n",
                        "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
                        "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "source": [
                "precision, recall, f1 = iterate_eval_model(lr_model, test_x_ids, test_x, test_y, test_topk_num)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "source": [
                "print(\"Precision: {:.4} \\t Recall: {:.4} \\t F1: {:.4}\".format(\n",
                "    precision, recall, f1\n",
                "))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Precision: 0.2731 \t Recall: 0.1888 \t F1: 0.2103\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}